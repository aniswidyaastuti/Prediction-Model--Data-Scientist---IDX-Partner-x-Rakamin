# -*- coding: utf-8 -*-
"""final task idx data scientist

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tmqxn2qGxEmfksrD6gfycGYp-GIJ3m55

##IMPORT LIBRARY
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, roc_curve, classification_report, confusion_matrix
)
import joblib

"""##BUSSINES UNDERSTANDING##

Business Understanding & Objectives
Objective: Predict credit default (Charged Off) to minimize loss.
Key metrics: Recall for default class, ROC-AUC overall.

##DATA UNDERSTANDING
"""

df = pd.read_csv('loan_data_2007_2014.csv')
print("Data shape:", df.shape)
print(df.dtypes)

df = df[df['loan_status'].isin(['Fully Paid', 'Charged Off'])]
print(f"Filtered data shape: {df.shape}")

"""MISSING VALUES"""

missing_counts = df.isnull().sum()
print("\nMissing values per column:\n", missing_counts)
pct_missing = (missing_counts / len(df) * 100).round(2)
print("\nMissing percentage per column:\n", pct_missing)

"""##DATA PREPARATION"""

# 3.1 Target definition
df['target'] = df['loan_status'].map({'Fully Paid': 0, 'Charged Off': 1})

# 3.2 Impute missing annual_inc
df['annual_inc'] = SimpleImputer(strategy='median').fit_transform(df[['annual_inc']])

# 3.3 Feature cleaning
# Extract term months
df['term_months'] = df['term'].astype(str).str.extract(r'(\d+)').astype(int)
# Clean interest rate
df['int_rate_clean'] = df['int_rate'].astype(str).str.rstrip('%').astype(float)

# 3.4 Drop outliers in annual_inc
iqr = df['annual_inc'].quantile(0.75) - df['annual_inc'].quantile(0.25)
lower = df['annual_inc'].quantile(0.25) - 1.5*iqr
upper = df['annual_inc'].quantile(0.75) + 1.5*iqr
df = df[(df['annual_inc'] >= lower) & (df['annual_inc'] <= upper)].copy()

# 3.5 Feature selection & encoding
features = ['loan_amnt', 'term_months', 'int_rate_clean', 'annual_inc', 'grade']
X = df[features].copy()
y = df['target'].copy()
# Encode grade to numeric
X['grade_encoded'] = LabelEncoder().fit_transform(X['grade'])
X.drop(columns=['grade'], inplace=True)

# 3.6 Scale numeric features
num_cols = ['loan_amnt', 'term_months', 'int_rate_clean', 'annual_inc']
X[num_cols] = StandardScaler().fit_transform(X[num_cols])

# 3.7 Train-test split (stratified)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

"""EXPLORATORY DATA ANALYSIS (EDA)"""

for col in num_cols + ['grade_encoded']:
    plt.figure()
    if col in num_cols:
        plt.hist(X[col], bins=30)
    else:
        plt.bar(X[col].value_counts().index, X[col].value_counts())
    plt.title(f'Distribution of {col}')
    plt.show()

corr = pd.concat([X, y.rename('target')], axis=1).corr()
plt.figure(figsize=(6,6))
plt.imshow(corr, aspect='auto')
plt.colorbar()
plt.xticks(range(len(corr)), corr.columns, rotation=90)
plt.yticks(range(len(corr)), corr.index)
plt.title('Correlation Matrix')
plt.tight_layout()
plt.show()

default_rate = y.groupby(X['grade_encoded']).mean()
plt.figure()
plt.bar(default_rate.index, default_rate.values)
plt.title('Default Rate by Grade')
plt.xlabel('Grade Encoded')
plt.ylabel('Default Rate')
plt.ylim(0,1)
plt.show()

"""##MODEL DEVELOPMENT"""

models = {
    'LogisticRegression': LogisticRegression(max_iter=1000),
    'RandomForest': RandomForestClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42),
    'GradientBoosting': GradientBoostingClassifier(random_state=42)
}
grids = {
    'LogisticRegression': {'C': [0.1, 1, 10]},
    'RandomForest': {'n_estimators': [100, 200], 'max_depth': [None, 10]},
    'SVM': {'C': [0.1, 1], 'kernel': ['linear']},
    'GradientBoosting': {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1]}
}
best_models = {}
for name, model in models.items():
    gs = GridSearchCV(model, grids[name], scoring='roc_auc', cv=5)
    gs.fit(X_train, y_train)
    best_models[name] = gs.best_estimator_
    print(f"Best {name} params: {gs.best_params_}")

"""##MODEL EVALUATION AND SELECTION"""

metrics = []
plt.figure(figsize=(8,6))
for name, model in best_models.items():
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:,1]
    metrics.append({
        'Model': name,
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred),
        'Recall': recall_score(y_test, y_pred),
        'F1': f1_score(y_test, y_pred),
        'ROC_AUC': roc_auc_score(y_test, y_proba)
    })
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, label=f"{name} (AUC={roc_auc_score(y_test,y_proba):.2f})")
plt.plot([0,1], [0,1], '--', color='gray')
plt.title('ROC Curves Comparison')
plt.legend()
plt.show()

metrics_df = pd.DataFrame(metrics).set_index('Model')
metrics_df[['Accuracy','Precision','Recall','F1']].plot(kind='bar', figsize=(10,6))
plt.title('Model Comparison: Accuracy, Precision, Recall, F1-score')
plt.ylim(0,1)
plt.show()

"""##KEY INSIGHT"""

Predictions & Insights
preds = best_models['GradientBoosting'].predict(X_test)
print("Classification Report for GB:\n",classification_report(y_test,preds))
cm=confusion_matrix(y_test,preds)
print("Confusion Matrix:\n",cm)
# Insight: proportion predicted default vs actual
default_prop=preds.mean(); actual_prop=y_test.mean()
print(f"Predicted default proportion: {default_prop:.2f}, actual: {actual_prop:.2f}")
# Top features from GB
importances=pd.Series(best_models['GradientBoosting'].feature_importances_,index=X.columns).sort_values(ascending=False)
print("Top 3 features driving default:",importances.head(3).to_dict())

"""##DEPLOYMENT"""

final_model = best_models['GradientBoosting']
final_model.fit(X, y)
joblib.dump(final_model, 'final_credit_risk_model.pkl')
print("Saved final_credit_risk_model.pkl for deployment")

